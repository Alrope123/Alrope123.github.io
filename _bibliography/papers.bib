---
---

@article{ lyu2025compactds,
  bibtex_show={true},
  title={Frustratingly Simple Retrieval Improves Challenging, Reasoning-Intensive Benchmarks},
  author={Lyu, Xinxi and Duan, Michael and Shao, Rulin and Koh, Pang and Min, Sewon}
  year={2025},
  selected={true}
}

@article{ lyu2024href,
  bibtex_show={true},
  title={ HREF: Human Response-Guided Evaluation of Instruction Following in Language Models },
  author={ Lyu, Xinxi and Wang, Yizhong and Hajishirzi, Hannaneh and Dasigi, Pradeep},
  year={ 2024 },
  selected={true}
}

@inproceedings{ lyu2023set,
  bibtex_show={true},
  title={ Leveraging Set Assumption for Membership Inference in Language Models },
  author={ Lyu, Xinxi and Min, Sewon and Holtzman, Ari and Mireshghallah, Niloofar and Elazar, Yanai and Hajishirzi, Hannaneh and Dasigi, Pradeep},
  year={ 2024 },
  selected={true}
}

@article{soldaini2024dolma,
  bibtex_show={true},
  arxiv={2402.00159},
  title={Dolma: An open corpus of three trillion tokens for language model pretraining research},
  author={Soldaini, Luca and Kinney, Rodney and Bhagia, Akshita and Schwenk, Dustin and Atkinson, David and Authur, Russell and Bogin, Ben and Chandu, Khyathi and Dumas, Jennifer and Elazar, Yanai and others},
  journal={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics},
  year={2024},
  selected={false}
}

@article{lambert2024t,
  bibtex_show={true},
  arxiv={2411.15124},
  title={TULU 3: Pushing Frontiers in Open Language Model Post-Training},
  author={Lambert, Nathan and Morrison, Jacob and Pyatkin, Valentina and Huang, Shengyi and Ivison, Hamish and Brahman, Faeze and Miranda, Lester James V and Liu, Alisa and Dziri, Nouha and Lyu, Xinxi and others},
  booktitle={arXiv preprint arXiv:2411.15124},
  year={2024},
  selected={true}
}

@article{min2023factscore,
  bibtex_show={true},
  arxiv={2305.14251},
  title={FActScore: Fine-grained Atomic Evaluation of Factual Precision in Long Form Text Generation},
  author={Min, Sewon and Krishna, Kalpesh and Lyu, Xinxi and Lewis, Mike and Yih, Wen-tau and Koh, Pang Wei and Iyyer, Mohit and Zettlemoyer, Luke and Hajishirzi, Hannaneh},
  journal={Empirical Methods in Natural Language Processing },
  year={2023},
  selected={true}
}

@article{lyu2022z,
  bibtex_show={true},
  arxiv={2212.09865},
  title={ Z-ICL: Zero-Shot In-Context Learning with Pseudo-Demonstrations },
  author={ Lyu, Xinxi and Min, Sewon and Beltagy, Iz and Zettlemoyer, Luke and Hajishirzi, Hannaneh },
  journal={ the Association for Computational Linguistics },
  year={2022},
  selected={true}
}

@article{ min2022rethinking,
  bibtex_show={true},
  arxiv={2202.12837},
  title={ Rethinking the Role of Demonstrations: What makes In-context Learning Work? },
  author={ Min, Sewon and Lyu, Xinxi and Holtzman, Ari and Artetxe, Mikel and Lewis, Mike and Hajishirzi, Hannaneh and Zettlemoyer, Luke },
  journal ={ Empirical Methods in Natural Language Processing },
  year={2022},
  selected={true}
}

@article{ khashabi2021prompt,
  bibtex_show={true},
  arxiv={2112.08348},
  title={ {P}rompt {W}aywardness: The Curious Case of Discretized Interpretation of Continuous Prompts },
  author={ Khashabi, Daniel and Lyu, Shane and Min, Sewon and Qin, Lianhui and Richardson, Kyle and Singh, Sameer and Welleck, Sean and Hajishirzi, Hannaneh and Khot, Tushar and Sabharwal, Ashish and Choi, Yejin },
  journal={ Conference of the North American Chapter of the Association for Computational Linguistics },
  year={2021},
  selected={true}
}
